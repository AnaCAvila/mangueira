
>[!summary] Summary
> Be VERY CRITICAL of yours and othersâ€™ work, and keep an eye on whether a review is biased, and make it reproducible.


>[!quote] Cited

## Authors:
[[Haddaway, Neal R.]], [[Bethel, Alison]], [[Dicks, Lynn V.]], [[Koricheva, Julia]], [[Macura, Biljana]], [[Petrokofsky, Gillian]], [[Pullin, Andrew S.]], [[Savilaakso, Sini]], [[Stewart, Gavin B.]]
## Notes:
1. Lack of relevance (involving the people and companies interested in the project)
2. Lack of a protocol (forgetting initial objectives)
3. Lack of transparency (can't be replicated)
4. Selection bias (not including the true breadth of knowledge in the topic)
	- include synonyms
	- using different tools
	- check for site bias; was something done predominately on tropical environments or more on temperate?

5. Publication bias (looking up grey literature)
	- grey literature is when reports are not commercially published. sometimes there are negative or nonconclusive results which are less likely to hit journals.

6. Lack of criticism ( not considering whether the studies you are reading do indeed convince you)
	- think critically whether the studies you are considered are plausible, and whether they have been criticized by past literature.

7. Inappropriate synthesis (wrong statistics)
	- meta-analysis is the combination of quantitative information from multiple studies - calculation of effect sizes, combined effects, confidence intervals... all to generate one summary estimate of all findings.
	- Some studies may not consider different effect sizes and statistical power of different studies.
	- Look up criteria for meta-analysis
	- Vote-counting when considering different studies with different conclusions over the same topic should NEVER be employed; instead, statistical methods and past critiques of each paper considered in the review must be taken into account.
	- If not able to do a meta-analysis, narrative synthesis are preferrable to vote-counting.

8. Not collaborating with others or having work double-checked.

### Notes and thoughts

- systematic reviews: supposed to reduce bias, but don't always. Are a more methodic way to review; question, protocol, search for papers, screen papers, take data, criticize, synthesize, and finally review/publish. May do those steps badly, or not do them at all.
- Issue with meta analyses: sometimes the data isn't really shared with reviewers, and a lot of data richness is lost. Mainly if you're doing a meta-analysis with too many studies; and it's important to read meta-analyses with skepticism.
- Be careful with trusting reviews - most of them don't fit the criteria of a systematic review.
- In well-written systematic reviews and meta-analyses you can see themes and trends more easily than by studying the entire field
- Bar-graphs are not a great way to display data - best to have all data points out of specific categories
- Reading past theses for reviews can be a great source of negative information and true data collection.

%% Import Date: 2023-10-06T17:31:33.066-04:00 %%
