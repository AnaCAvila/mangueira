"SmartSource:Floresta Aleatória/020 Técnicas de Otimização.md": {"path":"Floresta Aleatória/020 Técnicas de Otimização.md","class_name":"SmartSource","blocks":{"#":[2,9]},"mtime":1716750111570,"size":644,"hash":"081c490f95cf51d55689077ab966e3096d1227f4d6609495024ccfe13020388c","last_read_hash":"081c490f95cf51d55689077ab966e3096d1227f4d6609495024ccfe13020388c","outlinks":[{"title":"Avoiding Local Minima When Training A Machine Learning Model With TensorFlow – Surfactants","target":"https://www.surfactants.net/avoiding-local-minima-when-training-a-machine-learning-model-with-tensorflow/","line":3},{"title":"neural networks - How to avoid falling into the \"local minima\" trap? - Artificial Intelligence Stack Exchange","target":"https://ai.stackexchange.com/questions/1362/how-to-avoid-falling-into-the-local-minima-trap","line":6},{"title":"Gentle Introduction to the Adam Optimization Algorithm for Deep Learning - MachineLearningMastery.com","target":"https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/","line":8}],"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.03338885,0.0086746,0.02554976,0.0302897,0.04055883,0.05429739,-0.04931835,0.02486238,0.06096462,0.01341311,0.02561599,-0.06040536,0.00167869,0.08144516,0.01403216,0.01853609,-0.0650387,0.04409284,0.02946318,-0.01412228,0.06621863,0.00106285,-0.00193949,-0.04776895,0.03384654,-0.0081583,0.00076329,-0.00661738,-0.02261038,-0.2541194,0.05185661,-0.04647971,-0.04000872,-0.01040861,-0.0058816,0.01449036,0.00535077,0.02405065,-0.1000926,0.03016688,-0.02663476,0.04222867,-0.07433218,-0.04870098,0.0295631,-0.03220244,0.01505607,-0.08116325,-0.06966796,-0.00723231,-0.03544484,-0.02579895,0.00400994,-0.00037874,-0.01312795,0.00703288,0.07060985,0.05798498,0.01523941,0.04463339,0.03724225,0.06856108,-0.15202881,0.03731937,0.04615595,0.02865671,-0.01949602,0.00201977,0.05521669,0.0976625,-0.00910109,0.03229299,0.00769312,0.04842883,0.02363151,0.03966775,0.03027578,-0.0162945,0.0461661,-0.03331721,0.04929384,0.04107886,-0.04606775,-0.07563074,-0.0246753,-0.04961016,0.01117213,0.00566766,0.0330332,-0.02021174,-0.02567495,-0.06080562,-0.00402191,-0.0077213,-0.01555975,0.01575409,0.02592956,-0.00770826,-0.09069208,0.12244768,-0.03866879,-0.00777576,-0.00495535,0.02105947,-0.05667905,-0.02767847,-0.04936648,-0.04097413,0.00579568,-0.01339252,0.00355849,-0.02324294,0.02114971,-0.00771774,-0.01181764,-0.01152711,0.01819849,0.09719619,-0.00661396,0.05078867,-0.05813743,-0.00049466,0.09826925,0.01486573,0.03435981,-0.03995389,-0.07073355,0.06059504,0.01038058,0.03474054,0.04427176,-0.04099518,-0.04358333,-0.07172256,0.03688068,-0.02640053,0.02329782,0.00675063,-0.00889096,-0.05874703,-0.02841667,-0.02060809,0.07243299,-0.08032953,-0.05501699,0.11590391,-0.03790998,-0.034901,-0.01859571,-0.13370241,-0.02222635,-0.00106674,-0.07468559,-0.00908732,0.01213706,0.06037579,0.06786498,0.05902524,-0.14356141,0.0273617,-0.06686439,-0.01858332,-0.02643892,0.13619256,0.00438191,-0.04610401,-0.06065557,-0.04820972,-0.01104963,-0.00361562,0.07120556,0.0083693,0.01070898,-0.02044852,-0.00710956,0.02724843,-0.13437,-0.02803129,-0.06822649,-0.005638,-0.04329217,-0.0285478,0.02804401,-0.020797,0.00486185,0.02329815,0.03681875,-0.06358679,-0.03240043,-0.00997594,-0.08668156,-0.0383916,-0.01077547,0.00645597,-0.00626413,-0.02906642,0.02526856,0.01997587,0.00224503,-0.00332778,-0.01055444,0.01523573,0.02563896,0.02247062,0.04958495,-0.00613459,0.04373647,-0.01175083,0.08000222,0.07196505,-0.06514922,-0.02574704,0.03847664,-0.05724661,0.05974518,0.02113853,0.02987674,0.02587689,-0.03809561,0.04092546,0.08679544,0.02041966,-0.05646668,-0.18181777,-0.02664301,0.00117154,0.01886301,0.00745013,-0.09883816,0.05746036,-0.03569557,0.02799093,0.05025512,0.05911462,-0.01712869,-0.01801816,0.023843,-0.00831279,-0.00359135,0.03529785,0.00251428,0.007962,0.05626858,0.02927961,-0.00030387,0.01697553,-0.0499456,-0.00615453,-0.05200807,0.10499556,0.02684224,0.09567091,0.00737854,-0.04067667,0.03794063,-0.01682688,-0.0260405,0.02049686,-0.01173343,0.07393265,-0.03153211,0.02516332,0.00731837,0.01160408,0.08004622,0.00637698,-0.11937874,-0.08620654,-0.06519067,-0.04653367,0.01364087,-0.02724274,-0.01795628,0.01671394,-0.00243546,0.0655876,-0.04669824,0.00881151,-0.04403817,-0.07016037,0.00179141,-0.03258006,0.0179256,0.00945115,-0.07889367,-0.04866239,-0.05953082,0.05343399,0.00210357,0.02848842,-0.02994838,0.05596187,0.00827379,0.03873624,0.17297791,0.04142681,-0.0018123,0.03866342,0.00843964,0.06556775,-0.01028703,-0.06027561,-0.00138807,0.03828575,-0.00727403,0.05588043,0.05632465,-0.00556009,0.02755486,0.09293307,-0.05016797,-0.0034543,0.02744932,-0.00913187,0.01079762,-0.06654354,0.04014221,0.04859938,-0.02957185,-0.21314815,0.01052322,0.03266674,0.04335769,0.01547143,0.01423008,0.10939131,-0.00966935,-0.01341644,0.02847918,-0.08045087,0.00989606,0.05492641,0.03520022,0.01703346,0.00972784,0.00455463,0.00689589,0.07504694,-0.09219446,0.02902116,0.06476644,0.17901927,-0.03529824,-0.02066356,0.01034497,-0.02997471,0.02033992,0.04742325,-0.01137325,-0.03676242,0.03719404,0.11686173,-0.01305783,0.06684953,0.0734826,-0.01856377,-0.00949127,0.05778274,-0.01705603,0.00413299,-0.01469706,0.02245692,0.03878259,0.02021239,-0.02928226,-0.03635709,-0.03529943,-0.04242083,0.04134008,0.0256744,-0.00457056,0.00501953,-0.02837385,0.06011461,0.09483477,-0.0404889,-0.06618312,-0.08170622,-0.00872528,0.04480796,-0.0710232,0.0030971,-0.02414003,0.0019164],"tokens":196}}}
"SmartBlock:Floresta Aleatória/020 Técnicas de Otimização.md#": {"class_name":"SmartBlock","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.0317442,0.0042165,0.02816881,0.0260261,0.04290413,0.05490905,-0.05616526,0.02254618,0.06028051,0.01066111,0.02662441,-0.05921658,0.00522612,0.07748425,0.01482153,0.01997891,-0.06688147,0.04220498,0.03023451,-0.01150669,0.06657413,0.00117095,-0.0042845,-0.04430202,0.0330608,-0.00981973,0.00043562,-0.00899983,-0.02351242,-0.24985057,0.05567864,-0.04858264,-0.03350301,-0.00870906,-0.00397717,0.00963279,0.00471369,0.03095399,-0.09869788,0.02999173,-0.02627544,0.03610612,-0.07146681,-0.04227156,0.03167709,-0.03099864,0.0135969,-0.07898182,-0.06994028,-0.00724124,-0.04050301,-0.0298552,0.00694097,-0.00414158,-0.01162011,-0.00125402,0.06273253,0.05942009,0.01583742,0.04106096,0.03623706,0.06480436,-0.15035632,0.03302535,0.04546874,0.03101123,-0.0205446,-0.00255589,0.05698792,0.09942905,-0.00674992,0.03534019,0.00627721,0.05134036,0.02087602,0.03853045,0.03330474,-0.00928922,0.04892093,-0.03305769,0.05080571,0.03625564,-0.04529962,-0.07739181,-0.02867089,-0.04926477,0.00863387,0.00169022,0.03627831,-0.01718171,-0.03194539,-0.05764566,-0.00405393,-0.00485524,-0.01939509,0.0154597,0.02322791,-0.00572021,-0.09183956,0.12272234,-0.04129246,-0.01025446,-0.00416699,0.01441314,-0.05826044,-0.02737223,-0.04587616,-0.04174304,0.0027853,-0.01596085,0.00239294,-0.02220457,0.02708508,-0.00549905,-0.00862272,-0.01275738,0.02112496,0.10165614,-0.00946295,0.05532555,-0.06016992,0.00172067,0.09781073,0.01477992,0.03503655,-0.03732596,-0.07310592,0.06158264,0.0129546,0.03521489,0.04243234,-0.03860097,-0.04180694,-0.0728559,0.03828583,-0.02323316,0.02007514,0.0092697,-0.00641241,-0.06049946,-0.03456502,-0.02467404,0.07177368,-0.07934973,-0.05111633,0.11172324,-0.03521423,-0.03906925,-0.01813725,-0.13206086,-0.02217719,0.0026479,-0.08254797,-0.00861523,0.01159577,0.06363852,0.07234316,0.06328355,-0.1407907,0.02837455,-0.06385606,-0.02074886,-0.02893391,0.13830033,0.00078946,-0.05001887,-0.05635052,-0.047171,-0.01133901,0.00568818,0.06883343,0.01217765,0.00895846,-0.02327789,-0.01237652,0.02696752,-0.13945039,-0.0271218,-0.06278312,-0.00191724,-0.04330985,-0.02340108,0.02687864,-0.01757619,0.00620798,0.02208587,0.03613292,-0.06084076,-0.0325776,-0.0079412,-0.08707065,-0.03250315,-0.01746194,0.00623176,-0.00683902,-0.03183475,0.02699833,0.02218508,0.00117949,-0.00317198,-0.01024147,0.02379632,0.02546629,0.022813,0.04737709,-0.00544916,0.04131442,-0.01117773,0.07355086,0.07008658,-0.06528122,-0.02557624,0.03971446,-0.05888803,0.05785839,0.01775968,0.0272026,0.02153588,-0.04293014,0.04149549,0.08860118,0.02483081,-0.05734938,-0.1834615,-0.02660608,-0.00120947,0.01557324,0.01259147,-0.09844036,0.05762617,-0.03140577,0.02845107,0.04852887,0.06484752,-0.02082722,-0.01977288,0.02070364,-0.01403281,-0.00228339,0.03459134,0.00505926,0.00366093,0.06016202,0.02654305,0.00423447,0.01924263,-0.0498512,-0.00387661,-0.0556726,0.10489795,0.02990796,0.09549987,0.00799553,-0.03571075,0.04020381,-0.01797425,-0.0265111,0.02063293,-0.0136306,0.0745188,-0.02980378,0.02930476,0.01125109,0.01079857,0.07685438,0.00784956,-0.12363658,-0.08742493,-0.05968082,-0.05151767,0.01443059,-0.03028139,-0.01549315,0.01306958,-0.00728366,0.05807198,-0.04462565,0.00857308,-0.04561318,-0.06765404,-0.00280904,-0.03564264,0.01902735,0.01139858,-0.07796527,-0.04996572,-0.05477457,0.05817349,0.00135735,0.02836557,-0.0290335,0.05252448,0.00974124,0.04007599,0.17327268,0.04288033,-0.00090723,0.04526848,0.00468483,0.0648888,-0.00729133,-0.05743582,-0.00163305,0.03707962,-0.00493167,0.05241838,0.05559458,-0.00801325,0.02751965,0.08814739,-0.04896661,-0.00365376,0.02611561,-0.0103133,0.01993906,-0.06312183,0.04282267,0.04720856,-0.03071195,-0.21639714,0.01291949,0.03668302,0.0447145,0.01527201,0.01396264,0.10607696,-0.00892264,-0.01266367,0.02717492,-0.08310585,0.00937292,0.05469226,0.03402303,0.01852579,0.00657531,0.00526135,0.00954885,0.07811859,-0.09596055,0.02410709,0.07116508,0.17746764,-0.03804106,-0.0193997,0.01161395,-0.03159419,0.02131593,0.05009007,-0.00923366,-0.04277797,0.03689848,0.11746031,-0.01028997,0.06814083,0.0694365,-0.02040581,-0.01041029,0.05480946,-0.01632873,0.00097931,-0.0102603,0.01778634,0.03889503,0.0206116,-0.02451771,-0.03047117,-0.03504047,-0.04013933,0.03974251,0.03156456,-0.00733345,0.00684229,-0.02748165,0.06048465,0.09636422,-0.03829083,-0.0688081,-0.08076263,-0.01189748,0.04268207,-0.07339557,0.00786514,-0.02788813,-0.00412752],"tokens":195}},"key":"Floresta Aleatória/020 Técnicas de Otimização.md#","outlinks":[{"title":"Avoiding Local Minima When Training A Machine Learning Model With TensorFlow – Surfactants","target":"https://www.surfactants.net/avoiding-local-minima-when-training-a-machine-learning-model-with-tensorflow/","line":2},{"title":"neural networks - How to avoid falling into the \"local minima\" trap? - Artificial Intelligence Stack Exchange","target":"https://ai.stackexchange.com/questions/1362/how-to-avoid-falling-into-the-local-minima-trap","line":5},{"title":"Gentle Introduction to the Adam Optimization Algorithm for Deep Learning - MachineLearningMastery.com","target":"https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/","line":7}],"size":641,"hash":"9df30237ddb97f83633420b2fea6622bda6d08129c2b0d976eb7cdd2ba1f2e74"}